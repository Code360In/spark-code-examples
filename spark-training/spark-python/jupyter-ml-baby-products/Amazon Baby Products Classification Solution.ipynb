{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "\n",
    "First we load data from HDFS. It is stored as a trivial CSV file with three columns\n",
    "1. product name\n",
    "2. review text\n",
    "3. rating (1 - 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Planetwise Flannel Wipes</td>\n",
       "      <td>These flannel wipes are OK, but in my opinion ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>This is a product well worth the purchase.  I ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0                           Planetwise Flannel Wipes   \n",
       "1                              Planetwise Wipe Pouch   \n",
       "2                Annas Dream Full Quilt with 2 Shams   \n",
       "3  Stop Pacifier Sucking without tears with Thumb...   \n",
       "4  Stop Pacifier Sucking without tears with Thumb...   \n",
       "\n",
       "                                              review  rating  \n",
       "0  These flannel wipes are OK, but in my opinion ...       3  \n",
       "1  it came early and was not disappointed. i love...       5  \n",
       "2  Very soft and comfortable and warmer than it l...       5  \n",
       "3  This is a product well worth the purchase.  I ...       5  \n",
       "4  All of my kids have cried non-stop when I trie...       5  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "\n",
    "schema = StructType(\n",
    "    [\n",
    "        StructField('name', StringType(), True),\n",
    "        StructField('review', StringType(), True),\n",
    "        StructField('rating', IntegerType(), True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "raw_data = (\n",
    "    spark.read.option(\"header\", True)\n",
    "    .schema(schema)\n",
    "    .csv(\"s3a://dimajix-training/data/amazon_baby\")\n",
    ")\n",
    "raw_data.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean and Cache Data\n",
    "\n",
    "We need to clean up the data, since some reviews are NULL, and one of the downstream transformations apparently has some issues with NULL values.\n",
    "\n",
    "For helping distributing the workload, we repartition the DataFrame and also cache it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cloud b Gentle Giraffe On The Go Travel Sound ...</td>\n",
       "      <td>This is the best item ever to calm your baby t...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Evenflo Tribute 5 Convertible Car Seat, Ella</td>\n",
       "      <td>Cheap. Feels cheap too. Doesn't feel sturdy. H...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Britax Parkway SGL Booster Seat, Cardinal</td>\n",
       "      <td>Great product, well made, comfortable, and bei...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Boon Scrubble Interchangeable Bath Toy Squirt ...</td>\n",
       "      <td>These are great.  They are a tad bit hard to p...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Summer Infant By Your Side Sleeper Portable Be...</td>\n",
       "      <td>\"I just purchased this co sleeper, so I will l...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0  Cloud b Gentle Giraffe On The Go Travel Sound ...   \n",
       "1       Evenflo Tribute 5 Convertible Car Seat, Ella   \n",
       "2          Britax Parkway SGL Booster Seat, Cardinal   \n",
       "3  Boon Scrubble Interchangeable Bath Toy Squirt ...   \n",
       "4  Summer Infant By Your Side Sleeper Portable Be...   \n",
       "\n",
       "                                              review  rating  \n",
       "0  This is the best item ever to calm your baby t...       5  \n",
       "1  Cheap. Feels cheap too. Doesn't feel sturdy. H...       3  \n",
       "2  Great product, well made, comfortable, and bei...       5  \n",
       "3  These are great.  They are a tad bit hard to p...       5  \n",
       "4  \"I just purchased this co sleeper, so I will l...       4  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = (\n",
    "    raw_data.filter(col('rating').isNotNull())\n",
    "    .filter(col('review').isNotNull())\n",
    "    .repartition(31)\n",
    "    .cache()\n",
    ")\n",
    "\n",
    "data.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Sentiment\n",
    "\n",
    "Since we want to perform a classification (positive review vs negative review), we need to extract a binary sentiment value. We will map the ratings as follows:\n",
    "\n",
    "1. Ratings 1 and 2 count as a negative review\n",
    "2. Rating 3 counts as a neutral review\n",
    "3. Ratings 4 and 5 count as a positive review\n",
    "\n",
    "Since we want a binary classification, we will also remove neutral reviews altogether."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cloud b Gentle Giraffe On The Go Travel Sound ...</td>\n",
       "      <td>This is the best item ever to calm your baby t...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Britax Parkway SGL Booster Seat, Cardinal</td>\n",
       "      <td>Great product, well made, comfortable, and bei...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Boon Scrubble Interchangeable Bath Toy Squirt ...</td>\n",
       "      <td>These are great.  They are a tad bit hard to p...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Summer Infant By Your Side Sleeper Portable Be...</td>\n",
       "      <td>\"I just purchased this co sleeper, so I will l...</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Planet Wise Hanging Wet/Dry Diaper Bag, Black</td>\n",
       "      <td>I am an avid checker of product reviews, so I ...</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Kushies Waterproof Bib with Sleeves, Blue Circ...</td>\n",
       "      <td>Love this bib! The design is great and it work...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Evenflo Classic Johnny Jump Up, Frogs</td>\n",
       "      <td>We have two of door jumps - two different bran...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Baby Einstein Take Along Tunes</td>\n",
       "      <td>This has been a favorite of my daughters since...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>North States Supergate Classic Plastic Gate Mo...</td>\n",
       "      <td>I like the gate but hate my house. Unfortunate...</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Primo 4-In-1 Soft Seat Toilet Trainer and Step...</td>\n",
       "      <td>My daughter is 19 mos old (I got this about a ...</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0  Cloud b Gentle Giraffe On The Go Travel Sound ...   \n",
       "1          Britax Parkway SGL Booster Seat, Cardinal   \n",
       "2  Boon Scrubble Interchangeable Bath Toy Squirt ...   \n",
       "3  Summer Infant By Your Side Sleeper Portable Be...   \n",
       "4      Planet Wise Hanging Wet/Dry Diaper Bag, Black   \n",
       "5  Kushies Waterproof Bib with Sleeves, Blue Circ...   \n",
       "6              Evenflo Classic Johnny Jump Up, Frogs   \n",
       "7                     Baby Einstein Take Along Tunes   \n",
       "8  North States Supergate Classic Plastic Gate Mo...   \n",
       "9  Primo 4-In-1 Soft Seat Toilet Trainer and Step...   \n",
       "\n",
       "                                              review  rating  sentiment  \n",
       "0  This is the best item ever to calm your baby t...       5        1.0  \n",
       "1  Great product, well made, comfortable, and bei...       5        1.0  \n",
       "2  These are great.  They are a tad bit hard to p...       5        1.0  \n",
       "3  \"I just purchased this co sleeper, so I will l...       4        1.0  \n",
       "4  I am an avid checker of product reviews, so I ...       4        1.0  \n",
       "5  Love this bib! The design is great and it work...       5        1.0  \n",
       "6  We have two of door jumps - two different bran...       1        0.0  \n",
       "7  This has been a favorite of my daughters since...       5        1.0  \n",
       "8  I like the gate but hate my house. Unfortunate...       4        1.0  \n",
       "9  My daughter is 19 mos old (I got this about a ...       4        1.0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.filter(data.rating != 3)\n",
    "data = data.withColumn('sentiment', when(data.rating < 3, 0.0).otherwise(1.0))\n",
    "\n",
    "data.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Features from Reviews\n",
    "\n",
    "Now we want to split the review text into individual words, so we can create a \"bag of words\" model. In order to get a somewhat nice model, we also need to remove all punctuations from the reviews. This will be done as the first step using a user defined function (UDF) in PySpark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "\n",
    "def cleanup_text(text):\n",
    "    if text:\n",
    "        for c in string.punctuation:\n",
    "            text = text.replace(c, ' ')\n",
    "    return text\n",
    "\n",
    "\n",
    "remove_punctuation = udf(cleanup_text, StringType())\n",
    "data2 = data.withColumn('review', remove_punctuation('review'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Reviews into Words\n",
    "We could do that ourselves using the Python split method, but we use a Transformer provided by PySpark instead. Saves us some time and helps to create clean code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cloud b Gentle Giraffe On The Go Travel Sound ...</td>\n",
       "      <td>This is the best item ever to calm your baby t...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[this, is, the, best, item, ever, to, calm, yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Britax Parkway SGL Booster Seat, Cardinal</td>\n",
       "      <td>Great product  well made  comfortable  and bei...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[great, product, , well, made, , comfortable, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Boon Scrubble Interchangeable Bath Toy Squirt ...</td>\n",
       "      <td>These are great   They are a tad bit hard to p...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[these, are, great, , , they, are, a, tad, bit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0  Cloud b Gentle Giraffe On The Go Travel Sound ...   \n",
       "1          Britax Parkway SGL Booster Seat, Cardinal   \n",
       "2  Boon Scrubble Interchangeable Bath Toy Squirt ...   \n",
       "\n",
       "                                              review  rating  sentiment  \\\n",
       "0  This is the best item ever to calm your baby t...       5        1.0   \n",
       "1  Great product  well made  comfortable  and bei...       5        1.0   \n",
       "2  These are great   They are a tad bit hard to p...       5        1.0   \n",
       "\n",
       "                                               words  \n",
       "0  [this, is, the, best, item, ever, to, calm, yo...  \n",
       "1  [great, product, , well, made, , comfortable, ...  \n",
       "2  [these, are, great, , , they, are, a, tad, bit...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.feature import *\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(inputCol='review', outputCol='words')\n",
    "words = tokenizer.transform(data2)\n",
    "\n",
    "words.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Stop words\n",
    "\n",
    "We also want to remove so called stop words, which are all those tiny words which mainly serve as glue for building sentences. Usually they do not contain much information in a simple bag of words model. So we get rid of them.\n",
    "\n",
    "This is so common practice that PySpark already contains a Transformer for just doing that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>words</th>\n",
       "      <th>vwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cloud b Gentle Giraffe On The Go Travel Sound ...</td>\n",
       "      <td>This is the best item ever to calm your baby t...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[this, is, the, best, item, ever, to, calm, yo...</td>\n",
       "      <td>[best, item, ever, calm, your, baby, sleep, , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Britax Parkway SGL Booster Seat, Cardinal</td>\n",
       "      <td>Great product  well made  comfortable  and bei...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[great, product, , well, made, , comfortable, ...</td>\n",
       "      <td>[great, product, , well, made, , comfortable, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Boon Scrubble Interchangeable Bath Toy Squirt ...</td>\n",
       "      <td>These are great   They are a tad bit hard to p...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[these, are, great, , , they, are, a, tad, bit...</td>\n",
       "      <td>[these, great, , , they, tad, bit, hard, push,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0  Cloud b Gentle Giraffe On The Go Travel Sound ...   \n",
       "1          Britax Parkway SGL Booster Seat, Cardinal   \n",
       "2  Boon Scrubble Interchangeable Bath Toy Squirt ...   \n",
       "\n",
       "                                              review  rating  sentiment  \\\n",
       "0  This is the best item ever to calm your baby t...       5        1.0   \n",
       "1  Great product  well made  comfortable  and bei...       5        1.0   \n",
       "2  These are great   They are a tad bit hard to p...       5        1.0   \n",
       "\n",
       "                                               words  \\\n",
       "0  [this, is, the, best, item, ever, to, calm, yo...   \n",
       "1  [great, product, , well, made, , comfortable, ...   \n",
       "2  [these, are, great, , , they, are, a, tad, bit...   \n",
       "\n",
       "                                              vwords  \n",
       "0  [best, item, ever, calm, your, baby, sleep, , ...  \n",
       "1  [great, product, , well, made, , comfortable, ...  \n",
       "2  [these, great, , , they, tad, bit, hard, push,...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopWords = [\n",
    "    'the',\n",
    "    'a',\n",
    "    'and',\n",
    "    'or',\n",
    "    'it',\n",
    "    'this',\n",
    "    'of',\n",
    "    'an',\n",
    "    'as',\n",
    "    'in',\n",
    "    'on',\n",
    "    'is',\n",
    "    'are',\n",
    "    'to',\n",
    "    'was',\n",
    "    'for',\n",
    "    'then',\n",
    "    'i',\n",
    "]\n",
    "\n",
    "stopWordsRemover = StopWordsRemover(\n",
    "    inputCol='words', outputCol='vwords', stopWords=stopWords\n",
    ")\n",
    "vwords = stopWordsRemover.transform(words)\n",
    "\n",
    "vwords.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Bag of Words Features\n",
    "\n",
    "Finally we simply count the number of occurances of all words within the reviews. Again we can simply use a Transformer from PySpark to perform that task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "countVectorizer = CountVectorizer(inputCol='vwords', outputCol='features', minDF=2.0)\n",
    "countVectorizerModel = countVectorizer.fit(vwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Vocabulary\n",
    "\n",
    "The countVectorizerModel contains an implcit vocabulary containing all words. This can be useful for mapping features back to words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'my', 'that', 'with', 'we', 'have', 'but', 't', 'so', 's', 'not', 'you', 'baby', 'they', 'one', 'very', 'when', 'great', 'can', 'be', 'he', 'she', 'would', 'at', 'just', 'up', 'use', 'these', 'out', 'all', 'our', 'them', 'like', 'love', 'had', 'her', 'if', 'easy', 'has', 'little', 'seat', 'old', 'well', 'get', 'only', 'from', 'will', 'product', 'because', 'more']\n"
     ]
    }
   ],
   "source": [
    "print(countVectorizerModel.vocabulary[0:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tidy up DataFrame\n",
    "\n",
    "We now carry so many columns inside the DataFrame, let's remove some intermediate columns to get more focus on our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>vwords</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cloud b Gentle Giraffe On The Go Travel Sound ...</td>\n",
       "      <td>This is the best item ever to calm your baby t...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[best, item, ever, calm, your, baby, sleep, , ...</td>\n",
       "      <td>(2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Britax Parkway SGL Booster Seat, Cardinal</td>\n",
       "      <td>Great product  well made  comfortable  and bei...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[great, product, , well, made, , comfortable, ...</td>\n",
       "      <td>(5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Boon Scrubble Interchangeable Bath Toy Squirt ...</td>\n",
       "      <td>These are great   They are a tad bit hard to p...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[these, great, , , they, tad, bit, hard, push,...</td>\n",
       "      <td>(6.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0  Cloud b Gentle Giraffe On The Go Travel Sound ...   \n",
       "1          Britax Parkway SGL Booster Seat, Cardinal   \n",
       "2  Boon Scrubble Interchangeable Bath Toy Squirt ...   \n",
       "\n",
       "                                              review  rating  sentiment  \\\n",
       "0  This is the best item ever to calm your baby t...       5        1.0   \n",
       "1  Great product  well made  comfortable  and bei...       5        1.0   \n",
       "2  These are great   They are a tad bit hard to p...       5        1.0   \n",
       "\n",
       "                                              vwords  \\\n",
       "0  [best, item, ever, calm, your, baby, sleep, , ...   \n",
       "1  [great, product, , well, made, , comfortable, ...   \n",
       "2  [these, great, , , they, tad, bit, hard, push,...   \n",
       "\n",
       "                                            features  \n",
       "0  (2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1  (5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2  (6.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = countVectorizerModel.transform(vwords).drop('words')\n",
    "\n",
    "features.limit(3).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Train Data / Test Data\n",
    "\n",
    "Now let's do the usual split of our data into a training data set and a validation data set. Let's use 80% of all reviews for training and 20% for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data: 126874\n",
      "test_data: 31705\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = features.randomSplit([0.8, 0.2], seed=0)\n",
    "\n",
    "print(\"train_data: %d\" % train_data.count())\n",
    "print(\"test_data: %d\" % test_data.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Classifier\n",
    "\n",
    "There are many different classification algorithms out there. We will use a LogisticRegression, of course a DecisionTreeClassifier could be another interesting option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import *\n",
    "\n",
    "\n",
    "logisticRegression = LogisticRegression(featuresCol='features', labelCol='sentiment')\n",
    "logisticModel = logisticRegression.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Model\n",
    "The LogisticRegressionModel also uses coefficients mapped to individual words. Let's have a look at them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01168209  0.22786136  0.20238767  0.24145364  0.65199258  0.18077175\n",
      " -0.34238165 -2.41905135  0.60320699  0.39776083 -3.29387396 -0.06376773\n",
      "  0.07940401  0.21586512  0.23324266 -0.17306954  0.07453342  3.96279634\n",
      "  1.03241461 -0.13461789]\n"
     ]
    }
   ],
   "source": [
    "print(logisticModel.coefficients.toArray()[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number positive weights 18092\n",
      "Number negative weights 11196\n"
     ]
    }
   ],
   "source": [
    "numPositiveWeights = len(\n",
    "    list(filter(lambda x: x > 0, logisticModel.coefficients.toArray()))\n",
    ")\n",
    "numNegativeWeights = len(\n",
    "    list(filter(lambda x: x < 0, logisticModel.coefficients.toArray()))\n",
    ")\n",
    "\n",
    "print(\"Number positive weights %d\" % numPositiveWeights)\n",
    "print(\"Number negative weights %d\" % numNegativeWeights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Weights of some Words\n",
    "\n",
    "Let's check how coefficients look like for some clearly positive or negative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good : 1.937799\n",
      "great : 3.962796\n",
      "bad : -0.802468\n",
      "ugly : 2.498138\n"
     ]
    }
   ],
   "source": [
    "def print_word_weight(word):\n",
    "    index = countVectorizerModel.vocabulary.index(word)\n",
    "    weight = logisticModel.coefficients[index]\n",
    "    print('%s : %f' % (word, weight))\n",
    "\n",
    "\n",
    "print_word_weight('good')\n",
    "print_word_weight('great')\n",
    "print_word_weight('bad')\n",
    "print_word_weight('ugly')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Extreme Words\n",
    "\n",
    "Let us try to find the most positive and most negative word according to the weights. This can be achieved using numpy argmin function to find the index and the vocabulary to map the index to the actual word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worst word: mooing  value -141.764890\n",
      "Best word: breezes value 161.181740\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "worstWordIndex = np.argmin(logisticModel.coefficients.toArray())\n",
    "worstWord = countVectorizerModel.vocabulary[worstWordIndex]\n",
    "worstWeight = logisticModel.coefficients[worstWordIndex]\n",
    "print(\"Worst word: %s  value %f\" % (worstWord, worstWeight))\n",
    "\n",
    "bestWordIndex = np.argmax(logisticModel.coefficients.toArray())\n",
    "bestWord = countVectorizerModel.vocabulary[bestWordIndex]\n",
    "bestWeight = logisticModel.coefficients[bestWordIndex]\n",
    "print(\"Best word: %s value %f\" % (bestWord, bestWeight))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Predictions\n",
    "\n",
    "The primary idea is of course to make predictions of the sentiment using the learned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>vwords</th>\n",
       "      <th>rawPrediction</th>\n",
       "      <th>probability</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>As a mom of twins these holders are my favorit...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[mom, twins, these, holders, my, favorite, , t...</td>\n",
       "      <td>[-17.932458840780992, 17.932458840780992]</td>\n",
       "      <td>[1.6294163559712737e-08, 0.9999999837058364]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>He is real tough and has been hit several time...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[he, real, tough, has, been, hit, several, tim...</td>\n",
       "      <td>[-17.415478840064583, 17.415478840064583]</td>\n",
       "      <td>[2.7324588365491493e-08, 0.9999999726754117]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>I did a lot of reviews on all the play yards a...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[did, lot, reviews, all, play, yards, availabl...</td>\n",
       "      <td>[-70.40874225030952, 70.40874225030952]</td>\n",
       "      <td>[2.641628630667009e-31, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'The Insulated Sippy' by Eco Vessel Insulated ...</td>\n",
       "      <td>This is  was  my son s favorite sippy  We used...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[, , my, son, s, favorite, sippy, , we, used, ...</td>\n",
       "      <td>[1.082589017250085, -1.082589017250085]</td>\n",
       "      <td>[0.7469836180690544, 0.2530163819309455]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(1) Cresci Products Window Wedge (2 Per Pack) ...</td>\n",
       "      <td>The means of attaching to a window was pretty ...</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[means, attaching, window, pretty, straight, f...</td>\n",
       "      <td>[-3.739933618946556, 3.739933618946556]</td>\n",
       "      <td>[0.023204442690751417, 0.9767955573092485]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>*SPECIAL PROMOTION*The Art of CureTM *SAFETY K...</td>\n",
       "      <td>My toddler 2 yrs  he was drooling all over his...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[my, toddler, 2, yrs, , he, drooling, all, ove...</td>\n",
       "      <td>[-7.951579391667169, 7.951579391667169]</td>\n",
       "      <td>[0.00035198167784236385, 0.9996480183221577]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>*The Art of CureTM *SAFETY KNOTTED* - Mixed Co...</td>\n",
       "      <td>I can t say anything but WONDERFUL things abou...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[can, t, say, anything, but, wonderful, things...</td>\n",
       "      <td>[-62.246020447388446, 62.246020447388446]</td>\n",
       "      <td>[9.266096083825356e-28, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10 Piece Baby Rattle and Teether Toy Gift Set ...</td>\n",
       "      <td>bought it for my 3 month old  obviously she ll...</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[bought, my, 3, month, old, , obviously, she, ...</td>\n",
       "      <td>[-11.52526303479438, 11.52526303479438]</td>\n",
       "      <td>[9.877284697866307e-06, 0.9999901227153021]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1st Bday Girl Autograph Bear</td>\n",
       "      <td>I loved the idea of an autograph teddy bear th...</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[loved, idea, autograph, teddy, bear, that, my...</td>\n",
       "      <td>[-10.70198297372375, 10.70198297372375]</td>\n",
       "      <td>[2.2499769938835655e-05, 0.9999775002300613]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2 Inch Foam Bassinet Mattress - 16&amp;quot; x 32&amp;...</td>\n",
       "      <td>i so wanted to love this because it took me fo...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[so, wanted, love, because, took, me, forever,...</td>\n",
       "      <td>[10.377909578448454, -10.377909578448454]</td>\n",
       "      <td>[0.9999688887382504, 3.1111261749518125e-05]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0                                               None   \n",
       "1                                               None   \n",
       "2                                               None   \n",
       "3  'The Insulated Sippy' by Eco Vessel Insulated ...   \n",
       "4  (1) Cresci Products Window Wedge (2 Per Pack) ...   \n",
       "5  *SPECIAL PROMOTION*The Art of CureTM *SAFETY K...   \n",
       "6  *The Art of CureTM *SAFETY KNOTTED* - Mixed Co...   \n",
       "7  10 Piece Baby Rattle and Teether Toy Gift Set ...   \n",
       "8                       1st Bday Girl Autograph Bear   \n",
       "9  2 Inch Foam Bassinet Mattress - 16&quot; x 32&...   \n",
       "\n",
       "                                              review  rating  sentiment  \\\n",
       "0  As a mom of twins these holders are my favorit...       5        1.0   \n",
       "1  He is real tough and has been hit several time...       5        1.0   \n",
       "2  I did a lot of reviews on all the play yards a...       5        1.0   \n",
       "3  This is  was  my son s favorite sippy  We used...       5        1.0   \n",
       "4  The means of attaching to a window was pretty ...       4        1.0   \n",
       "5  My toddler 2 yrs  he was drooling all over his...       5        1.0   \n",
       "6  I can t say anything but WONDERFUL things abou...       5        1.0   \n",
       "7  bought it for my 3 month old  obviously she ll...       4        1.0   \n",
       "8  I loved the idea of an autograph teddy bear th...       4        1.0   \n",
       "9  i so wanted to love this because it took me fo...       2        0.0   \n",
       "\n",
       "                                              vwords  \\\n",
       "0  [mom, twins, these, holders, my, favorite, , t...   \n",
       "1  [he, real, tough, has, been, hit, several, tim...   \n",
       "2  [did, lot, reviews, all, play, yards, availabl...   \n",
       "3  [, , my, son, s, favorite, sippy, , we, used, ...   \n",
       "4  [means, attaching, window, pretty, straight, f...   \n",
       "5  [my, toddler, 2, yrs, , he, drooling, all, ove...   \n",
       "6  [can, t, say, anything, but, wonderful, things...   \n",
       "7  [bought, my, 3, month, old, , obviously, she, ...   \n",
       "8  [loved, idea, autograph, teddy, bear, that, my...   \n",
       "9  [so, wanted, love, because, took, me, forever,...   \n",
       "\n",
       "                               rawPrediction  \\\n",
       "0  [-17.932458840780992, 17.932458840780992]   \n",
       "1  [-17.415478840064583, 17.415478840064583]   \n",
       "2    [-70.40874225030952, 70.40874225030952]   \n",
       "3    [1.082589017250085, -1.082589017250085]   \n",
       "4    [-3.739933618946556, 3.739933618946556]   \n",
       "5    [-7.951579391667169, 7.951579391667169]   \n",
       "6  [-62.246020447388446, 62.246020447388446]   \n",
       "7    [-11.52526303479438, 11.52526303479438]   \n",
       "8    [-10.70198297372375, 10.70198297372375]   \n",
       "9  [10.377909578448454, -10.377909578448454]   \n",
       "\n",
       "                                    probability  prediction  \n",
       "0  [1.6294163559712737e-08, 0.9999999837058364]         1.0  \n",
       "1  [2.7324588365491493e-08, 0.9999999726754117]         1.0  \n",
       "2                  [2.641628630667009e-31, 1.0]         1.0  \n",
       "3      [0.7469836180690544, 0.2530163819309455]         0.0  \n",
       "4    [0.023204442690751417, 0.9767955573092485]         1.0  \n",
       "5  [0.00035198167784236385, 0.9996480183221577]         1.0  \n",
       "6                  [9.266096083825356e-28, 1.0]         1.0  \n",
       "7   [9.877284697866307e-06, 0.9999901227153021]         1.0  \n",
       "8  [2.2499769938835655e-05, 0.9999775002300613]         1.0  \n",
       "9  [0.9999688887382504, 3.1111261749518125e-05]         0.0  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = logisticModel.transform(test_data)\n",
    "\n",
    "pred.drop('features').limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the most Positive Review\n",
    "\n",
    "Using the column rawPrediction, we can find the review which has the highest positive prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>vwords</th>\n",
       "      <th>features</th>\n",
       "      <th>rawPrediction</th>\n",
       "      <th>probability</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BabyPlus Prenatal Education System</td>\n",
       "      <td>I started wearing the Babyplus when I was 18 ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[, started, wearing, babyplus, when, 18, weeks...</td>\n",
       "      <td>(123.0, 5.0, 0.0, 1.0, 2.0, 0.0, 3.0, 3.0, 2.0...</td>\n",
       "      <td>[-433.31092507126573, 433.31092507126573]</td>\n",
       "      <td>[6.538171273697786e-189, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P'Kolino Silly Soft Seating in Tias, Green</td>\n",
       "      <td>I ve purchased both the P Kolino Little Reader...</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[ve, purchased, both, p, kolino, little, reade...</td>\n",
       "      <td>(61.0, 9.0, 4.0, 4.0, 3.0, 4.0, 8.0, 2.0, 0.0,...</td>\n",
       "      <td>[-423.4328898048961, 423.4328898048961]</td>\n",
       "      <td>[1.2747719578282095e-184, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UPPAbaby Cruz Stroller, Denny</td>\n",
       "      <td>I have the 2012 model  and have been using it ...</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[have, 2012, model, , have, been, using, 8, mo...</td>\n",
       "      <td>(177.0, 14.0, 15.0, 12.0, 2.0, 6.0, 12.0, 6.0,...</td>\n",
       "      <td>[-381.801368396545, 381.801368396545]</td>\n",
       "      <td>[1.5338133811104968e-166, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chariot 2011 Cabriolet Bicycle Trailer **CLOSE...</td>\n",
       "      <td>We were looking for a bike trailer   JUST a bi...</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[we, were, looking, bike, trailer, , , just, b...</td>\n",
       "      <td>(185.0, 5.0, 16.0, 11.0, 5.0, 6.0, 16.0, 10.0,...</td>\n",
       "      <td>[-348.18818234818536, 348.18818234818536]</td>\n",
       "      <td>[6.078462507294663e-152, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Roan Rocco Classic Pram Stroller 2-in-1 with B...</td>\n",
       "      <td>Great Pram Rocco      I bought this pram from ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[great, pram, rocco, , , , , , bought, pram, f...</td>\n",
       "      <td>(67.0, 3.0, 5.0, 6.0, 4.0, 3.0, 2.0, 5.0, 4.0,...</td>\n",
       "      <td>[-342.70461393419976, 342.70461393419976]</td>\n",
       "      <td>[1.4631108994202463e-149, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Evenflo 6 Pack Classic Glass Bottle, 4-Ounce</td>\n",
       "      <td>It s always fun to write a review on those pro...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[s, always, fun, write, review, those, product...</td>\n",
       "      <td>(219.0, 9.0, 16.0, 13.0, 13.0, 4.0, 12.0, 8.0,...</td>\n",
       "      <td>[-337.6993363255923, 337.6993363255923]</td>\n",
       "      <td>[2.1829394596232316e-147, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0                 BabyPlus Prenatal Education System   \n",
       "1         P'Kolino Silly Soft Seating in Tias, Green   \n",
       "2                      UPPAbaby Cruz Stroller, Denny   \n",
       "3  Chariot 2011 Cabriolet Bicycle Trailer **CLOSE...   \n",
       "4  Roan Rocco Classic Pram Stroller 2-in-1 with B...   \n",
       "5       Evenflo 6 Pack Classic Glass Bottle, 4-Ounce   \n",
       "\n",
       "                                              review  rating  sentiment  \\\n",
       "0   I started wearing the Babyplus when I was 18 ...       5        1.0   \n",
       "1  I ve purchased both the P Kolino Little Reader...       4        1.0   \n",
       "2  I have the 2012 model  and have been using it ...       4        1.0   \n",
       "3  We were looking for a bike trailer   JUST a bi...       4        1.0   \n",
       "4  Great Pram Rocco      I bought this pram from ...       5        1.0   \n",
       "5  It s always fun to write a review on those pro...       5        1.0   \n",
       "\n",
       "                                              vwords  \\\n",
       "0  [, started, wearing, babyplus, when, 18, weeks...   \n",
       "1  [ve, purchased, both, p, kolino, little, reade...   \n",
       "2  [have, 2012, model, , have, been, using, 8, mo...   \n",
       "3  [we, were, looking, bike, trailer, , , just, b...   \n",
       "4  [great, pram, rocco, , , , , , bought, pram, f...   \n",
       "5  [s, always, fun, write, review, those, product...   \n",
       "\n",
       "                                            features  \\\n",
       "0  (123.0, 5.0, 0.0, 1.0, 2.0, 0.0, 3.0, 3.0, 2.0...   \n",
       "1  (61.0, 9.0, 4.0, 4.0, 3.0, 4.0, 8.0, 2.0, 0.0,...   \n",
       "2  (177.0, 14.0, 15.0, 12.0, 2.0, 6.0, 12.0, 6.0,...   \n",
       "3  (185.0, 5.0, 16.0, 11.0, 5.0, 6.0, 16.0, 10.0,...   \n",
       "4  (67.0, 3.0, 5.0, 6.0, 4.0, 3.0, 2.0, 5.0, 4.0,...   \n",
       "5  (219.0, 9.0, 16.0, 13.0, 13.0, 4.0, 12.0, 8.0,...   \n",
       "\n",
       "                               rawPrediction                     probability  \\\n",
       "0  [-433.31092507126573, 433.31092507126573]   [6.538171273697786e-189, 1.0]   \n",
       "1    [-423.4328898048961, 423.4328898048961]  [1.2747719578282095e-184, 1.0]   \n",
       "2      [-381.801368396545, 381.801368396545]  [1.5338133811104968e-166, 1.0]   \n",
       "3  [-348.18818234818536, 348.18818234818536]   [6.078462507294663e-152, 1.0]   \n",
       "4  [-342.70461393419976, 342.70461393419976]  [1.4631108994202463e-149, 1.0]   \n",
       "5    [-337.6993363255923, 337.6993363255923]  [2.1829394596232316e-147, 1.0]   \n",
       "\n",
       "   prediction  \n",
       "0         1.0  \n",
       "1         1.0  \n",
       "2         1.0  \n",
       "3         1.0  \n",
       "4         1.0  \n",
       "5         1.0  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract one component from a Vectors\n",
    "extract_from_vector = udf(lambda v, i: float(v[i]), FloatType())\n",
    "\n",
    "positives = pred.orderBy(extract_from_vector(pred.rawPrediction, lit(1)).desc())\n",
    "\n",
    "positives.limit(6).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of Prediction\n",
    "\n",
    "Again we want to assess the performance of the prediction model. This can be done using the builtin class BinaryClassificationEvaluator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8755224793908036\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import *\n",
    "\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol='sentiment')\n",
    "result = evaluator.evaluate(pred)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Evaluator\n",
    "\n",
    "We want to use a different metric namely accuracy. Accuracy is defined as\n",
    "\n",
    "    number_correct_predictions / total_number_predictions\n",
    "    \n",
    "First let us directly calculate that metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.884151\n"
     ]
    }
   ],
   "source": [
    "num_total = pred.count()\n",
    "num_correct = pred.filter(pred.sentiment == pred.prediction).count()\n",
    "\n",
    "model_accuracy = float(num_correct) / num_total\n",
    "\n",
    "print(\"Model Accuracy: %f\" % (float(num_correct) / num_total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare with Dummy Predictor\n",
    "\n",
    "It is always interesting to see how a trivial prediction performs. The trivial predictor simply predicts the most common class for all objects. In this case this would be a positive review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 0.846428\n"
     ]
    }
   ],
   "source": [
    "num_total = pred.count()\n",
    "num_positive = pred.filter(pred.sentiment == 1.0).count()\n",
    "\n",
    "baseline_accuracy = float(num_positive) / num_total\n",
    "\n",
    "print(\"Baseline Accuracy: %f\" % (float(num_positive) / num_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "PySpark 2.4 (Python 3)",
   "language": "python",
   "name": "pyspark3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
