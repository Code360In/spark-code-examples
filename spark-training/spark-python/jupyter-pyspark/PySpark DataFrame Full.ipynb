{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 Spark Session\n",
    "\n",
    "Before working with Spark, we need an entry point. The so called *Spark Session* allows us to create DataFrames etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-10-200-101-50.eu-central-1.compute.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f937abaa780>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "if not 'spark' in locals():\n",
    "    spark = (\n",
    "        SparkSession.builder.master(\"local[*]\")\n",
    "        .config(\"spark.driver.memory\", \"64G\")\n",
    "        .getOrCreate()\n",
    "    )\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Creating a DataFrame\n",
    "\n",
    "First, let's create some DataFrame from Python objects. While this is probably not the most common thing to do, it is easy and helpful in some situations where you already have some Python objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(name='Alice', age=13), Row(name='Bob', age=12)]\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame([('Alice', 13), ('Bob', 12)], ['name', 'age'])\n",
    "print(df.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to create a PySpark DataFrame from an existing PySpark RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(name='Alice', age=13), Row(name='Bob', age=12)]\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.parallelize([('Alice', 13), ('Bob', 12)])\n",
    "df = spark.createDataFrame(rdd, ['name', 'age'])\n",
    "print(df.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PySpark also contains a small method for displaying the contents of a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+\n",
      "| name|age|\n",
      "+-----+---+\n",
      "|Alice| 13|\n",
      "|  Bob| 12|\n",
      "+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Inspect Schema\n",
    "\n",
    "The `spark` object has different methods for creating a so called Spark DataFrame object. This object is similar to a table, it contains rows of records, which all conform to a common schema with named columns and specific types. On the surface it heavily borrows concepts from Pandas DataFrames or R DataFrames, although the syntax and many operations are syntactically very different.\n",
    "\n",
    "As the first step, we want to see the contents of the DataFrame. This can be easily done by using the show method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Explicitly specify Schema\n",
    "\n",
    "It is also possible to explicitly specify the schema, not only by names, but also by types. This is quite useful in the next steps when we want to load data from CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+\n",
      "| name|age|\n",
      "+-----+---+\n",
      "|Alice| 13|\n",
      "|  Bob| 12|\n",
      "+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "\n",
    "data = [('Alice', 13), ('Bob', 12)]\n",
    "schema = StructType(\n",
    "    [\n",
    "        StructField('name', StringType(), True),\n",
    "        StructField('age', IntegerType(), True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "df = spark.createDataFrame(data, schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+\n",
      "| name|age|\n",
      "+-----+---+\n",
      "|Alice| 23|\n",
      "|  Bob| 21|\n",
      "+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "\n",
    "Person = Row('name', 'age')\n",
    "alice = Person('Alice', 23)\n",
    "bob = Person('Bob', 21)\n",
    "df = spark.createDataFrame([alice, bob])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Reading Data\n",
    "\n",
    "Of course manually creating DataFrames from a couple of records is not the real use case. Instead we want to read data frames files.. Spark supports various file formats, we will use JSON in the following example.\n",
    "\n",
    "The entrypoint for creating Spark objects is an object called spark which is provided in the notebook and read to use. We will read a file containing some informations on a couple of persons, which will serve as the basis for the next examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Read JSON data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-------+------+\n",
      "|age|height|   name|   sex|\n",
      "+---+------+-------+------+\n",
      "| 14|   156|  Alice|female|\n",
      "| 21|   181|    Bob|  male|\n",
      "| 27|   176|Charlie|  male|\n",
      "| 24|   167|    Eve|female|\n",
      "| 19|   172|Frances|female|\n",
      "| 31|   191| George|  male|\n",
      "+---+------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "persons = spark.read.json(\"s3://dimajix-training/data/persons.json\")\n",
    "persons.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: long (nullable = true)\n",
      " |-- height: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "persons.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Reading CSV Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-------+------+\n",
      "|age|height|   name|   sex|\n",
      "+---+------+-------+------+\n",
      "| 23|   156|  Alice|female|\n",
      "| 21|   181|    Bob|  male|\n",
      "| 27|   176|Charlie|  male|\n",
      "| 24|   167|    Eve|female|\n",
      "| 19|   172|Frances|female|\n",
      "| 31|   191| George|female|\n",
      "+---+------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "persons = (\n",
    "    spark.read.option(\"inferSchema\", True)\n",
    "    .option(\"header\", True)\n",
    "    .csv(\"s3://dimajix-training/data/persons_header.csv\")\n",
    ")\n",
    "persons.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- height: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "persons.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Explicit Schema\n",
    "\n",
    "We already saw that we can explicitly specify a schema when we create a DataFrame from a Python list of objects. We can also specify a schema when we read data from a storage. This is highly recommended, otherwise Spark would use automatic schema inference, which might hide problems of a changed data delivery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>156</td>\n",
       "      <td>Alice</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>181</td>\n",
       "      <td>Bob</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27</td>\n",
       "      <td>176</td>\n",
       "      <td>Charlie</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>167</td>\n",
       "      <td>Eve</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>172</td>\n",
       "      <td>Frances</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>31</td>\n",
       "      <td>191</td>\n",
       "      <td>George</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  height     name     sex\n",
       "0   23     156    Alice  female\n",
       "1   21     181      Bob    male\n",
       "2   27     176  Charlie    male\n",
       "3   24     167      Eve  female\n",
       "4   19     172  Frances  female\n",
       "5   31     191   George  female"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "\n",
    "schema = StructType(\n",
    "    [\n",
    "        StructField(\"age\", LongType(), False),\n",
    "        StructField(\"height\", LongType(), False),\n",
    "        StructField(\"name\", StringType(), False),\n",
    "        StructField(\"sex\", StringType(), False),\n",
    "    ]\n",
    ")\n",
    "\n",
    "persons = (\n",
    "    spark.read.option(\"header\", True)\n",
    "    .schema(schema)\n",
    "    .csv(\"s3://dimajix-training/data/persons_header.csv\")\n",
    ")\n",
    "\n",
    "persons.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: long (nullable = true)\n",
      " |-- height: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "persons.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Interacting with Pandas\n",
    "\n",
    "Now that we can create and read Spark DataFrames, we also want to convert them into Pandas DataFrames. Pandas is a Python package which also offers a concept called *DataFrame*, but that has nothing to do with Spark. Actually Pandas is much older than Spark, and Spark borrowed many ideas and concepts from Pandas (and from R of course).\n",
    "\n",
    "Nevertheless it is quite useful to convert a Spark DataFrame into a Pandas DataFrame, specifically because the Jupyter Notebook directly supports Pandas DataFrames and renders them much nicer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>156</td>\n",
       "      <td>Alice</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>181</td>\n",
       "      <td>Bob</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27</td>\n",
       "      <td>176</td>\n",
       "      <td>Charlie</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>167</td>\n",
       "      <td>Eve</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>172</td>\n",
       "      <td>Frances</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>31</td>\n",
       "      <td>191</td>\n",
       "      <td>George</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  height     name     sex\n",
       "0   23     156    Alice  female\n",
       "1   21     181      Bob    male\n",
       "2   27     176  Charlie    male\n",
       "3   24     167      Eve  female\n",
       "4   19     172  Frances  female\n",
       "5   31     191   George  female"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf = persons.toPandas()\n",
    "pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas also supports graphics, so we can create a (in thius case meaningless) graph of a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f1fe7351860>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "pdf.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention: Beware of huge DatFrames!\n",
    "\n",
    "Do not forget hat Apache Spark has been designed and built to handle really huge data sets, which do not need to fit into memory. Spark DataFrames con contain billions of rows and are stored in a distributed way on many nodes in a cluster. Actually the contents do not even need to be physically present at all, as long as the input data is accessible.\n",
    "\n",
    "But calling the toPandas() method will transfer all the records to a single machine (where the Jupyter Notebook runs on) - but maybe this computer does not have enough memory to hold all the data. In this case, you risk that the notebook process will crash with an Out-Of-Memory error (OOM). So you should only use toPandas() when you are really sure that the DataFrame contains a limited amount of records.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Simple Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Projections\n",
    "\n",
    "The simplest thing to do is to create a new DataFrame with a subset of the available columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bob</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charlie</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Eve</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Frances</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>George</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name  age\n",
       "0    Alice   23\n",
       "1      Bob   21\n",
       "2  Charlie   27\n",
       "3      Eve   24\n",
       "4  Frances   19\n",
       "5   George   31"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "\n",
    "result = persons.select('name', col('age'))\n",
    "result.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Addressing Columns\n",
    "\n",
    "Spark supports multiple different ways for addressing a columns. We just saw one way, but also the following methods are supported for specifying a column:\n",
    "\n",
    "* `df.column_name`\n",
    "* `df['column_name']`\n",
    "* `col('column_name')`\n",
    "* `df[idx]`\n",
    "\n",
    "All these methods return a Column object, which is an abstract representative of the data in the column. As we will see soon, transformations can be applied to Column in order to derive new values.\n",
    "\n",
    "### Beware of Lowercase and Uppercase\n",
    "\n",
    "While PySpark itself is case insenstive concering column names, Python itself is case sensitive. Since the first method for addressing columns by treating them as fields of a Python object *is* Python syntax, this is also case sensitive!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charlie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Eve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Frances</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>George</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name\n",
       "0    Alice\n",
       "1      Bob\n",
       "2  Charlie\n",
       "3      Eve\n",
       "4  Frances\n",
       "5   George"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = persons.select(persons.name)\n",
    "result.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Transformations \n",
    "\n",
    "The `select` method actually accepts any column object. A column object conceptually represents a column in a DataFrame. The column may either refer directly to an existing column of the input DataFrame, or it may represent the result of a calculation or transformation of one or multiple columns of the input DataFrame. For example if we simply want to transform the name into upper case, we can do so by using a function `upper` provided by PySpark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>upper(name)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice</td>\n",
       "      <td>ALICE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bob</td>\n",
       "      <td>BOB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charlie</td>\n",
       "      <td>CHARLIE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Eve</td>\n",
       "      <td>EVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Frances</td>\n",
       "      <td>FRANCES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>George</td>\n",
       "      <td>GEORGE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name upper(name)\n",
       "0    Alice       ALICE\n",
       "1      Bob         BOB\n",
       "2  Charlie     CHARLIE\n",
       "3      Eve         EVE\n",
       "4  Frances     FRANCES\n",
       "5   George      GEORGE"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = persons.select(persons[\"name\"], upper(persons[\"name\"]))\n",
    "result.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining new Column Names\n",
    "The resulting DataFrame again has a schema, but the column names to not look very nice. But by using the `alias` method of a `Column` object, you can immediately rename the newly created column like you are already used to in SQL with `SELECT complex_operation(...) AS nice_name FROM ...`. \n",
    "\n",
    "Technically specifying a new name for the resulting column is not required (as we already saw above), if the name is not specified, PySpark will generate a name from the expression. But since this generated name tends to be rather long and contains the logic instead of the intention, it is highly recommended to always explicitly specify the name of the resulting column using `as`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>upper_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice</td>\n",
       "      <td>ALICE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bob</td>\n",
       "      <td>BOB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charlie</td>\n",
       "      <td>CHARLIE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Eve</td>\n",
       "      <td>EVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Frances</td>\n",
       "      <td>FRANCES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>George</td>\n",
       "      <td>GEORGE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name upper_name\n",
       "0    Alice      ALICE\n",
       "1      Bob        BOB\n",
       "2  Charlie    CHARLIE\n",
       "3      Eve        EVE\n",
       "4  Frances    FRANCES\n",
       "5   George     GEORGE"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = persons.select(persons[\"name\"], upper(persons[\"name\"]).alias('upper_name'))\n",
    "result.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also perform simple mathematical calculations like addition, multiplication etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "result = persons.select(\n",
    "    persons['name'], (persons['height'] * 0.3937008).alias(\"height_inch\")\n",
    ")\n",
    "\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice_23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bob_21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charlie_27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Eve_24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Frances_19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>George_31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name_age\n",
       "0    Alice_23\n",
       "1      Bob_21\n",
       "2  Charlie_27\n",
       "3      Eve_24\n",
       "4  Frances_19\n",
       "5   George_31"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = persons.select(\n",
    "    concat(persons[\"name\"], lit('_'), persons[\"age\"].cast('string')).alias('name_age')\n",
    ")\n",
    "result.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>even</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>odd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>even</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>odd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>even</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>odd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>even</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>odd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>even</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>odd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number  text\n",
       "0       0  even\n",
       "1       1   odd\n",
       "2       2  even\n",
       "3       3   odd\n",
       "4       4  even\n",
       "5       5   odd\n",
       "6       6  even\n",
       "7       7   odd\n",
       "8       8  even\n",
       "9       9   odd"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers = spark.createDataFrame([(x,) for x in range(0, 10)], ['number'])\n",
    "result = numbers.select(\n",
    "    numbers[\"number\"],\n",
    "    when(numbers[\"number\"] % 2 == 0, 'even').otherwise('odd').alias('text'),\n",
    ")\n",
    "\n",
    "result.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salutation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mrs Alice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mr Bob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mr Charlie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mrs Eve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mrs Frances</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mrs George</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    salutation\n",
       "0    Mrs Alice\n",
       "1       Mr Bob\n",
       "2   Mr Charlie\n",
       "3      Mrs Eve\n",
       "4  Mrs Frances\n",
       "5   Mrs George"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = persons.select(\n",
    "    concat(\n",
    "        when(persons[\"sex\"] == 'male', \"Mr \").otherwise(\"Mrs \"), persons[\"name\"]\n",
    "    ).alias(\"salutation\")\n",
    ")\n",
    "result.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Functions\n",
    "\n",
    "You can find the full list of available functions at [PySpark SQL Module](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#module-pyspark.sql.functions). Commonly used functions for example are as follows:\n",
    "\n",
    "* [`concat(*cols)`](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.functions.concat) - Concatenates multiple input columns together into a single column.\n",
    "* [`substring(col,start,len)`](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.functions.substring) - Substring starts at pos and is of length len when str is String type or returns the slice of byte array that starts at pos in byte and is of length len when str is Binary type.\n",
    "* [`instr(col,substr)`](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.functions.instr) - Locate the position of the first occurrence of substr column in the given string. Returns null if either of the arguments are null.\n",
    "* [`locate(col,substr, pos)`](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.functions.locate) - Locate the position of the first occurrence of substr in a string column, after position pos.\n",
    "* [`length(col)`](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.functions.length) - Computes the character length of string data or number of bytes of binary data. \n",
    "* [`upper(col)`](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.functions.upper) - Converts a string column to upper case.\n",
    "* [`lower(col)`](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.functions.lower) - Converts a string column to lower case.\n",
    "* [`coalesce(*cols)`](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.functions.coalesce) - Returns the first column that is not null.\n",
    "* [`isnull(col)`](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.functions.isnull) - An expression that returns true iff the column is null.\n",
    "* [`isnan(col)`](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.functions.isnan) - An expression that returns true iff the column is NaN.\n",
    "* [`hash(cols*)`](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.functions.hash) - Calculates the hash code of given columns.\n",
    "\n",
    "Spark also supports conditional expressions, like the SQL `CASE WHEN` construct\n",
    "* [`when(condition, value)`](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.functions.when) - Evaluates a list of conditions and returns one of multiple possible result expressions.\n",
    "\n",
    "There are also some special functions often required\n",
    "* [`col(str)`](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.functions.col) - Returns a Column based on the given column name.\n",
    "* [`lit(val)`](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.functions.lit) - Creates a Column of literal value.\n",
    "* [`expr(str)`](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.functions.expr) - Parses the expression string into the column that it represents\n",
    "\n",
    "### User Defined Functions\n",
    "Unfortunately you cannot directly use normal Python functions for transforming DataFrame columns. Although PySpark already provides many useful functions, this might not always sufficient. But fortunately you can *convert* a standard Python function into a PySpark function, thereby defining a so called *user defined function* (UDF). Details will be explained in detail in the training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Injecting Literal Values\n",
    "\n",
    "Sometimes it is required to inkect literal values (i.e. strings or numbers) into a transformation expression. Since using simply a string could mean wither a column with that name or the literal itself, Spark offers the function `lit` to explicitly mark a string (or any other value) as a literal. `lit` creates a PySpark column object from the value. This means that all column methods are avilable for the literal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Name:Alice Age:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Name:Bob Age:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Name:Charlie Age:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Name:Eve Age:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Name:Frances Age:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Name:George Age:31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  text\n",
       "0    Name:Alice Age:23\n",
       "1      Name:Bob Age:21\n",
       "2  Name:Charlie Age:27\n",
       "3      Name:Eve Age:24\n",
       "4  Name:Frances Age:19\n",
       "5   Name:George Age:31"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = persons.select(\n",
    "    concat(lit('Name:'), persons.name, lit(' Age:'), persons.age).alias('text')\n",
    ")\n",
    "result.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Exercises\n",
    "\n",
    "Write a small `select` statement, which puts either \"Mr\" or \"Mrs\" into a new column called \"salutation\" depending on the sex of the person "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "## YOU CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6 SQL Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "result = persons.select(\n",
    "    expr(\"CASE WHEN sex = 'male' THEN 'Mr' ELSE 'Mrs' END AS salutation\")\n",
    ")\n",
    "\n",
    "result.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.7 Adding Columns\n",
    "\n",
    "A special variant of a `select` statement is the `withColumn` method. While the `select` statement requires all resulting columns to be defined in as arguments, the `withColumn` method keeps all existing columns and adds a new one. This operation is quite useful since in many cases new columns are derived from the existing ones, while the old ones still should be contained in the result.\n",
    "\n",
    "Let us have a look at a simple example, which only adds the salutation as a new column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>even</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>odd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>even</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>odd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>even</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>odd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>even</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>odd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>even</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>odd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number  text\n",
       "0       0  even\n",
       "1       1   odd\n",
       "2       2  even\n",
       "3       3   odd\n",
       "4       4  even\n",
       "5       5   odd\n",
       "6       6  even\n",
       "7       7   odd\n",
       "8       8  even\n",
       "9       9   odd"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = persons.withColumn(\n",
    "    \"salutation\", when(persons.sex == \"male\", 'Mr').otherwise('Mrs')\n",
    ")\n",
    "result.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the example above, `withColumn` always takes two arguments: The first one is the name of the new column (and it has to be a string), and the second argument is the expression containing the logic for calculating the actual contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "result = persons.select(\n",
    "    persons['*'], when(persons.sex == \"male\", 'Mr').otherwise('Mrs').alias(\"salutation\")\n",
    ")\n",
    "result.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.8 Dropping a Column\n",
    "\n",
    "PySpark also supports the opposite operation which simply removes some columns from a dataframe. This is useful if you need to remove some sensitive data before saving it to disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>even</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>odd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>even</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>odd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>even</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>odd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>even</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>odd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>even</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>odd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text\n",
       "0  even\n",
       "1   odd\n",
       "2  even\n",
       "3   odd\n",
       "4  even\n",
       "5   odd\n",
       "6  even\n",
       "7   odd\n",
       "8  even\n",
       "9   odd"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2 = result.drop(\"name\", \"age\")\n",
    "result2.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.9 Exercise\n",
    "\n",
    "Using the `persons` DataFrame, perform the following operations:\n",
    "* Add a new column `status` which should be `minor` if the person is younger than 21 and `adult` otherwise\n",
    "* Replace the column `name` by a new column `hashed_name` containing the hash value of the name\n",
    "* Drop the column `sex`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Filtering\n",
    "\n",
    "*Filtering* denotes the process of keeping only rows which meet a certain filter criteria. PySpark support two different approaches. The first approach specifies the filtering expression as a PySpark expression using columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>156</td>\n",
       "      <td>Alice</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>176</td>\n",
       "      <td>Charlie</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>167</td>\n",
       "      <td>Eve</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>191</td>\n",
       "      <td>George</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  height     name     sex\n",
       "0   23     156    Alice  female\n",
       "1   27     176  Charlie    male\n",
       "2   24     167      Eve  female\n",
       "3   31     191   George  female"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = persons.filter(persons.age > 22)\n",
    "result.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second approach simply uses a string containing an SQL expression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>156</td>\n",
       "      <td>Alice</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>176</td>\n",
       "      <td>Charlie</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>167</td>\n",
       "      <td>Eve</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>191</td>\n",
       "      <td>George</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  height     name     sex\n",
       "0   23     156    Alice  female\n",
       "1   27     176  Charlie    male\n",
       "2   24     167      Eve  female\n",
       "3   31     191   George  female"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = persons.filter(\"age > 22\")\n",
    "result.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using SQL expressions, you can also work with aliases to address specific DataFrames in case of ambiguous column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "result = persons.alias(\"persons\").filter(\"persons.age > 22 AND height < 170\")\n",
    "result.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Exercise\n",
    "\n",
    "Perform two different filter operations:\n",
    "1. Select all women with a height of at least 160\n",
    "2. Select all persons which are younger than 23 or older than 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Limit Operations\n",
    "\n",
    "When working with large datasets, it may be helpful to limit the amount of records (like an SQL `LIMIT` operation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "result = persons.limit(3)\n",
    "result.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df = spark.createDataFrame([(x,) for x in range(0, 100)], ['value'])\n",
    "df.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest aggregation is the number of records in a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark supports the usual aggregations as we know from SQL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "      <th>avg</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4950</td>\n",
       "      <td>49.5</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sum   avg  min  max  count\n",
       "0  4950  49.5    0   99    100"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = df.select(\n",
    "    sum(df.value).alias('sum'),\n",
    "    avg(df.value).alias('avg'),\n",
    "    min(df.value).alias('min'),\n",
    "    max(df.value).alias('max'),\n",
    "    count(df.value).alias('count'),\n",
    ")\n",
    "result.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 Making Data Distinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bob</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name\n",
       "0    Bob\n",
       "1  Alice\n",
       "2    Bob"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.createDataFrame([('Bob',), ('Alice',), ('Bob',)], ['name'])\n",
    "df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name\n",
       "0    Bob\n",
       "1  Alice"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = df.distinct()\n",
    "result.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 Grouping & Aggregating\n",
    "\n",
    "An important class of operation is grouping and aggregation, which is equivalnt to an SQL `SELECT aggregation GROUP BY grouping` statement. In PySpark, grouping and aggregation is always performed by first creating groups using `groupBy` immediately followed by aggregation expressions inside an `agg` method. (Actually there are also some predefined aggregations which can be used instead of `agg`, but they do not offer the flexiviliby which is required most of the time).\n",
    "\n",
    "Note that in the `agg` method you only need to specify the aggregation expression, the grouping columns are added automatically by PySpark to the resulting DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>avg_age</th>\n",
       "      <th>min_height</th>\n",
       "      <th>max_height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female</td>\n",
       "      <td>24.25</td>\n",
       "      <td>156</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>24.00</td>\n",
       "      <td>176</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sex  avg_age  min_height  max_height\n",
       "0  female    24.25         156         191\n",
       "1    male    24.00         176         181"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = persons.groupBy(persons.sex).agg(\n",
    "    avg(persons.age).alias('avg_age'),\n",
    "    min(persons.height).alias('min_height'),\n",
    "    max(persons.height).alias('max_height'),\n",
    ")\n",
    "result.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes it may be useful to access all elements of a group as a list. But since `groupBy` does not return a normal DataFrame and requires an aggregate function as the next step, this requires a small trick. Using the `collect_list` function, you can put all elemenets of a single column of every group into a new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female</td>\n",
       "      <td>[(Alice, 23), (Eve, 24), (Frances, 19), (Georg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>[(Bob, 21), (Charlie, 27)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sex                                               list\n",
       "0  female  [(Alice, 23), (Eve, 24), (Frances, 19), (Georg...\n",
       "1    male                         [(Bob, 21), (Charlie, 27)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = persons.groupBy(persons.sex).agg(\n",
    "    collect_list(struct(persons.name, persons.age)).alias(\"list\")\n",
    ")\n",
    "result.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "result.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation Functions\n",
    "\n",
    "PySpark supports many aggregation functions, they can be found in the documentation at [PySpark Function Documentation](http://spark.apache.org/docs/latest/api/python/pyspark.sql.html#module-pyspark.sql.functions). Aggregation functions are marked as such in the documentation, unfortunately there is no simple overview. Among common aggregation functions, there are for example:\n",
    "\n",
    "* min / max\n",
    "* count\n",
    "* sum\n",
    "* avg\n",
    "* stddev\n",
    "* variance\n",
    "* corr\n",
    "* first\n",
    "* last"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 Exercise\n",
    "\n",
    "Using the `persons` DataFrame, calculate the average height and the number of records per sex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9 Sorting Data\n",
    "\n",
    "PySpark also supports sorting data with the `orderBy` method. For example we can sort all persons by their height as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>156</td>\n",
       "      <td>Alice</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>167</td>\n",
       "      <td>Eve</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>172</td>\n",
       "      <td>Frances</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>176</td>\n",
       "      <td>Charlie</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>181</td>\n",
       "      <td>Bob</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>31</td>\n",
       "      <td>191</td>\n",
       "      <td>George</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  height     name     sex\n",
       "0   23     156    Alice  female\n",
       "1   24     167      Eve  female\n",
       "2   19     172  Frances  female\n",
       "3   27     176  Charlie    male\n",
       "4   21     181      Bob    male\n",
       "5   31     191   George  female"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = persons.orderBy(persons.height)\n",
    "result.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If nothing else is specified, PySpark will sort the records in increasing order of the sort columns. If you require descending order, this can be specified by manipulating the sort column with the `desc()` method as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31</td>\n",
       "      <td>191</td>\n",
       "      <td>George</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>176</td>\n",
       "      <td>Charlie</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>167</td>\n",
       "      <td>Eve</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>156</td>\n",
       "      <td>Alice</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>181</td>\n",
       "      <td>Bob</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19</td>\n",
       "      <td>172</td>\n",
       "      <td>Frances</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  height     name     sex\n",
       "0   31     191   George  female\n",
       "1   27     176  Charlie    male\n",
       "2   24     167      Eve  female\n",
       "3   23     156    Alice  female\n",
       "4   21     181      Bob    male\n",
       "5   19     172  Frances  female"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = persons.orderBy(persons.age.desc())\n",
    "result.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1 Exercise\n",
    "\n",
    "As an exercise we want to sort all persons first by their sex and then by their descening age. Sorting by multiple columns can easily be achieved by specifying multiple columns as arguments in the `orderBy` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 Joining Data\n",
    "\n",
    "Every relation algebra also contains join operations which lets you combine multiple tables by a matching criterion. PySpark also supports joins of multiple DataFrames. In order to shed some light on that, we need a second DataFrame in addition to the `persons` DataFrame. Therefore we load some address data as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hamburg</td>\n",
       "      <td>Alice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Frankfurt</td>\n",
       "      <td>Bob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Berlin</td>\n",
       "      <td>Henry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        city   name\n",
       "0    Hamburg  Alice\n",
       "1  Frankfurt    Bob\n",
       "2     Berlin  Henry"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addresses = spark.read.json(\"s3://dimajix-training/data/addresses.json\")\n",
    "addresses.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the addresses DataFrame, we want to combine it with the persons DataFrame such that the city of every person is added as a new column. This is achieved by the join method which essentially takes two parameters: The first parameter specifies the second DataFrame to join with, and the second parameter specifies the join condition. In this case we want to join all records, where the name column matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>city</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>156</td>\n",
       "      <td>Alice</td>\n",
       "      <td>female</td>\n",
       "      <td>Hamburg</td>\n",
       "      <td>Alice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>181</td>\n",
       "      <td>Bob</td>\n",
       "      <td>male</td>\n",
       "      <td>Frankfurt</td>\n",
       "      <td>Bob</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  height   name     sex       city   name\n",
       "0   23     156  Alice  female    Hamburg  Alice\n",
       "1   21     181    Bob    male  Frankfurt    Bob"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = persons.join(addresses, persons.name == addresses.name)\n",
    "result.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let me make some relevant remarks:\n",
    "\n",
    "* The resulting DataFrame now contains two `name` columns - one comes from the `persons` DataFrame, the other from the `addresses` DataFrame. Since the join condition could have used some more complex expression, this behaviour is only logical since PySpark cannot assume that all joins simply use directly some column value. For example we could also have transformed the column on the fly by converting the name to upper case directly inside the join condition.\n",
    "* The result contains only persons where an address was found, although the original `persons` DataFrame contained more persons.\n",
    "* There are no records of addresses without any person, although the `addresses` DataFrame contains information about some persons not available in the `persons` DataFrame.\n",
    "\n",
    "So let us first address the first observation. We can easily get rid of the copied `name` column by either performing an explicit select of the desired columns, or by dropping the duplicate columns. Since PySpark records the lineage of every column, the duplicate `name` columns can be addressed by their original DataFrame even after the join operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice</td>\n",
       "      <td>23</td>\n",
       "      <td>Hamburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bob</td>\n",
       "      <td>21</td>\n",
       "      <td>Frankfurt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name  age       city\n",
       "0  Alice   23    Hamburg\n",
       "1    Bob   21  Frankfurt"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = persons.join(addresses, persons.name == addresses.name).drop(addresses.name)\n",
    "result.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.1 Join Types\n",
    "\n",
    "Now let us explain the last two observations. These are due to the used join type, which was a so called *inner* join. In this case, only records with information from both DataFrames are included in the result.\n",
    "\n",
    "In addition to the *inner* join, PySpark also supports some additional joins:\n",
    "* *outer join* will contain records for all elements from both DataFrames. If either the left or right DataFrames doesn't contain any information, the result will contain `None` values (= `NULL` values) for the corresponding columns.\n",
    "* In a *right join*, the second DataFrame (the right DataFrame) as specified as an argument is the leading element. The result will contain records for every record in that DataFrame.\n",
    "* In a *left join*, the first DataFrame (the left DataFrame) as specified as the object iteself is the leading element. The result will contain records for every record in that DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Charlie</td>\n",
       "      <td>27.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bob</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Frankfurt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alice</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Hamburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Eve</td>\n",
       "      <td>24.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>George</td>\n",
       "      <td>31.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Frances</td>\n",
       "      <td>19.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Berlin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name   age       city\n",
       "0  Charlie  27.0       None\n",
       "1      Bob  21.0  Frankfurt\n",
       "2    Alice  23.0    Hamburg\n",
       "3      Eve  24.0       None\n",
       "4   George  31.0       None\n",
       "5  Frances  19.0       None\n",
       "6     None   NaN     Berlin"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = persons.join(addresses, persons.name == addresses.name, how=\"outer\")\n",
    "result.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Hamburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bob</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Frankfurt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Berlin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name   age       city\n",
       "0  Alice  23.0    Hamburg\n",
       "1    Bob  21.0  Frankfurt\n",
       "2   None   NaN     Berlin"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = persons.join(addresses, persons.name == addresses.name, how=\"right\")\n",
    "result.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice</td>\n",
       "      <td>23</td>\n",
       "      <td>Hamburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bob</td>\n",
       "      <td>21</td>\n",
       "      <td>Frankfurt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charlie</td>\n",
       "      <td>27</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Eve</td>\n",
       "      <td>24</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Frances</td>\n",
       "      <td>19</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>George</td>\n",
       "      <td>31</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name  age       city\n",
       "0    Alice   23    Hamburg\n",
       "1      Bob   21  Frankfurt\n",
       "2  Charlie   27       None\n",
       "3      Eve   24       None\n",
       "4  Frances   19       None\n",
       "5   George   31       None"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = persons.join(addresses, persons.name == addresses.name, how=\"left\")\n",
    "result.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.2 Join on Column\n",
    "\n",
    "As a convenience, Spark also supports directly joining on a column that is present in both DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>sex</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Charlie</td>\n",
       "      <td>27.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>male</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bob</td>\n",
       "      <td>21.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Frankfurt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alice</td>\n",
       "      <td>23.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>female</td>\n",
       "      <td>Hamburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Eve</td>\n",
       "      <td>24.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>female</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>George</td>\n",
       "      <td>31.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>female</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Frances</td>\n",
       "      <td>19.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>female</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Henry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>Berlin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name   age  height     sex       city\n",
       "0  Charlie  27.0   176.0    male       None\n",
       "1      Bob  21.0   181.0    male  Frankfurt\n",
       "2    Alice  23.0   156.0  female    Hamburg\n",
       "3      Eve  24.0   167.0  female       None\n",
       "4   George  31.0   191.0  female       None\n",
       "5  Frances  19.0   172.0  female       None\n",
       "6    Henry   NaN     NaN    None     Berlin"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = persons.join(addresses, [\"name\"], how=\"outer\")\n",
    "result.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.3 Exercise\n",
    "\n",
    "As an exercise, we use another DataFrame loaded from a file called `lastnames.json`, which can be joined to the persons DataFrame again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>last_name</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Liddell</td>\n",
       "      <td>Alice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baumeister</td>\n",
       "      <td>Bob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gates</td>\n",
       "      <td>Bob</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    last_name   name\n",
       "0     Liddell  Alice\n",
       "1  Baumeister    Bob\n",
       "2       Gates    Bob"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lastnames = spark.read.json(\"s3://dimajix-training/data/lastnames.json\")\n",
    "lastnames.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now join the lastnames DataFrame to the `persons` DataFrame whenever the `name` column of both DataFrames matches. Note what happens due to the fact that we have two last names for \"Bob\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11 Set Operations\n",
    "\n",
    "Spark also offers some set operations, like `UNION`, `INTERSECT` and `SUBTRACT`.\n",
    "\n",
    "First let us create two simple data frames for experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df1 = spark.createDataFrame(\n",
    "    [['Alice', 23], ['Bob', 44], ['Charlie', 31]], [\"name\", \"age\"]\n",
    ")\n",
    "\n",
    "df2 = spark.createDataFrame([['Alice', 23], ['Bob', 44], ['Henry', 31]], [\"name\", \"age\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.1 Unions\n",
    "\n",
    "The most well known operation is a `union` which actually corresponds to an SQL `UNION ALL`, i.e. it will keep duplicate records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bob</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charlie</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alice</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bob</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Henry</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name  age\n",
       "0    Alice   23\n",
       "1      Bob   44\n",
       "2  Charlie   31\n",
       "3    Alice   23\n",
       "4      Bob   44\n",
       "5    Henry   31"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = df1.union(df2)\n",
    "result.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you do not want to keep duplicate records, you can simply run a `distinct()` transformation after the `union()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Henry</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charlie</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bob</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name  age\n",
       "0    Alice   23\n",
       "1    Henry   31\n",
       "2  Charlie   31\n",
       "3      Bob   44"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = df1.union(df2).distinct()\n",
    "result.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Union and UnionByName\n",
    "\n",
    "A simple `union` operation simply takes the schema of the first DataFrame and appends the records of the second data frame. The columns will be matched by their position and types will be changed if required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df3 = spark.createDataFrame([[23, 'Alice'], [44, 'Bob'], [31, 'Henry']], [\"age\", \"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bob</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charlie</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>Alice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44</td>\n",
       "      <td>Bob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>31</td>\n",
       "      <td>Henry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name    age\n",
       "0    Alice     23\n",
       "1      Bob     44\n",
       "2  Charlie     31\n",
       "3       23  Alice\n",
       "4       44    Bob\n",
       "5       31  Henry"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = df1.union(df3)\n",
    "result.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bob</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charlie</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alice</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bob</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Henry</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name  age\n",
       "0    Alice   23\n",
       "1      Bob   44\n",
       "2  Charlie   31\n",
       "3    Alice   23\n",
       "4      Bob   44\n",
       "5    Henry   31"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = df1.unionByName(df3)\n",
    "result.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.2 Intersect and Subtract\n",
    "\n",
    "Spark also supports additional set operations like `INTERSECT` and `SUBTRACT`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bob</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name  age\n",
       "0  Alice   23\n",
       "1    Bob   44"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = df1.intersect(df2)\n",
    "result.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Charlie</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name  age\n",
       "0  Charlie   31"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = df1.subtract(df2)\n",
    "result.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12 Caching Data\n",
    "\n",
    "In some situations, you may want to persist intermediate results. For example iterative algorithms may benefit from *caching* intermediate results, if the same DataFrame is transformed again and again. Spark provides some capabilities to persist intermediate results using the methods `cache()` or `persist(storageLevel)`.\n",
    "\n",
    "Note that also caching is lazy, which means that records will not be created at the time when you call `cache()` or `persist()` but at the first time when the DataFrame is evaluated. This could be even a simple `count()` action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "persons.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "persons.storageLevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "persons.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "persons.storageLevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "persons.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13 Using SQL\n",
    "\n",
    "PySpark also directly supports SQL. In order to work with SQL, you only need to register a PySpark DataFrame as a *temporary view*, which provides a name to a DataFrame which can be referenced in SQL queries later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "persons = spark.read.json(\"s3://dimajix-training/data/persons.json\")\n",
    "addresses = spark.read.json(\"s3://dimajix-training/data/addresses.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>156</td>\n",
       "      <td>Alice</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>181</td>\n",
       "      <td>Bob</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27</td>\n",
       "      <td>176</td>\n",
       "      <td>Charlie</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>167</td>\n",
       "      <td>Eve</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>172</td>\n",
       "      <td>Frances</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>31</td>\n",
       "      <td>191</td>\n",
       "      <td>George</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  height     name     sex\n",
       "0   23     156    Alice  female\n",
       "1   21     181      Bob    male\n",
       "2   27     176  Charlie    male\n",
       "3   24     167      Eve  female\n",
       "4   19     172  Frances  female\n",
       "5   31     191   George  female"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persons.createOrReplaceTempView(\"persons\")\n",
    "\n",
    "result = spark.sql(\"SELECT * FROM persons\")\n",
    "result.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.1 Exercise\n",
    "\n",
    "Perform the following tasks, in order to join `persons` with `addresses`in SQL:\n",
    "\n",
    "* Register `addresses` DataFrame as `addresses`\n",
    "* Join `persons` with `addresses`\n",
    "* Only select persons which are 21 years or older"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14 User Defined Functions\n",
    "\n",
    "From time to time you hit a wall where you need a simple transformation, but Spark does not offer an appropriate function in the `pyspark.sql.functions` module. Fortunately you can simply define new functions, so called *user defined functions* or short *UDFs*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice &amp; Bob</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thelma &amp; Louise</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name  age\n",
       "0      Alice & Bob   12\n",
       "1  Thelma & Louise   17"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "\n",
    "df = spark.createDataFrame(\n",
    "    [('Alice & Bob', 12), ('Thelma & Louise', 17)], ['name', 'age']\n",
    ")\n",
    "df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thelma &amp; Louise'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import html\n",
    "\n",
    "\n",
    "html.escape(\"Thelma & Louise\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.1 Classic Python UDF\n",
    "\n",
    "First we will create a classical Python UDF (as opposed to a Pandas UDF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>html_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice &amp;amp; Bob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thelma &amp;amp; Louise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             html_name\n",
       "0      Alice &amp; Bob\n",
       "1  Thelma &amp; Louise"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_encode = udf(html.escape, StringType())\n",
    "\n",
    "result = df.select(html_encode('name').alias('html_name'))\n",
    "result.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an alternative, you can also use a Python decorator for declaring a UDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>html_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice &amp;amp; Bob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thelma &amp;amp; Louise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             html_name\n",
       "0      Alice &amp; Bob\n",
       "1  Thelma &amp; Louise"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@udf(StringType())\n",
    "def html_encode(s):\n",
    "    return html.escape(s)\n",
    "\n",
    "\n",
    "result = df.select(html_encode('name').alias('html_name'))\n",
    "result.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>both_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Alice &amp; Bob, Alice &amp;amp; Bob)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Thelma &amp; Louise, Thelma &amp;amp; Louise)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               both_names\n",
       "0          (Alice & Bob, Alice &amp; Bob)\n",
       "1  (Thelma & Louise, Thelma &amp; Louise)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@udf(\n",
    "    StructType(\n",
    "        [StructField(\"org_name\", StringType()), StructField(\"html_name\", StringType())]\n",
    "    )\n",
    ")\n",
    "def html_encode(s):\n",
    "    return (s, html.escape(s))\n",
    "\n",
    "\n",
    "result = df.select(html_encode('name').alias('both_names'))\n",
    "result.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wanto to use the Python UDF inside a SQL query, you also need to register it, so PySpark knows its name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>html_encode(name)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice &amp;amp; Bob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thelma &amp;amp; Louise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     html_encode(name)\n",
       "0      Alice &amp; Bob\n",
       "1  Thelma &amp; Louise"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_encode = spark.udf.register(\"html_encode\", html.escape, StringType())\n",
    "\n",
    "df.createOrReplaceTempView(\"famous_pairs\")\n",
    "result = spark.sql(\"SELECT html_encode(name) FROM famous_pairs\")\n",
    "result.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.2 Pandas UDFs\n",
    "\n",
    "\"Normal\" Python UDFs are pretty expensive (in terms of execution time), since for every record the following steps need to be performed:\n",
    "* record is serialized inside JVM\n",
    "* record is sent to an external Python process\n",
    "* record is deserialized inside Python\n",
    "* record is Processed in Python\n",
    "* result is serialized in Python\n",
    "* result is sent back to JVM\n",
    "* result is deserialized and stored inside result DataFrame\n",
    "\n",
    "This does not only sound like a lot of work, it actually is. Therefore Python UDFs are a magnitude slower than native UDFs written in Scala or Java, which run directly inside the JVM.\n",
    "\n",
    "But since Spark 2.3 an alternative approach is available for defining Python UDFs with so called *Pandas UDFs*. Pandas is a commonly used Python framework which also offers DataFrames (but Pandas DataFrames, not Spark DataFrames). Spark 2.3 now can convert inside the JVM a Spark DataFrame into a shareable memory buffer by using a library called *Arrow*. Python then can also treat this memory buffer as a Pandas DataFrame and can directly work on this shared memory.\n",
    "\n",
    "This approach has two major advantages:\n",
    "* No need for serialization and deserialization, since data is shared directly in memory between the JVM and Python\n",
    "* Pandas has lots of very efficient implementations in C for many functions\n",
    "\n",
    "Due to these two facts, Pandas UDFs are much faster and should be preferred over traditional Python UDFs whenever possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>height_inch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>156</td>\n",
       "      <td>Alice</td>\n",
       "      <td>female</td>\n",
       "      <td>61.417356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>181</td>\n",
       "      <td>Bob</td>\n",
       "      <td>male</td>\n",
       "      <td>71.259881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27</td>\n",
       "      <td>176</td>\n",
       "      <td>Charlie</td>\n",
       "      <td>male</td>\n",
       "      <td>69.291376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>167</td>\n",
       "      <td>Eve</td>\n",
       "      <td>female</td>\n",
       "      <td>65.748067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>172</td>\n",
       "      <td>Frances</td>\n",
       "      <td>female</td>\n",
       "      <td>67.716572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>31</td>\n",
       "      <td>191</td>\n",
       "      <td>George</td>\n",
       "      <td>female</td>\n",
       "      <td>75.196891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  height     name     sex  height_inch\n",
       "0   23     156    Alice  female    61.417356\n",
       "1   21     181      Bob    male    71.259881\n",
       "2   27     176  Charlie    male    69.291376\n",
       "3   24     167      Eve  female    65.748067\n",
       "4   19     172  Frances  female    67.716572\n",
       "5   31     191   George  female    75.196891"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "\n",
    "\n",
    "# Use udf to define a row-at-a-time udf\n",
    "@udf('double')\n",
    "# Input/output are both a single double value\n",
    "def cm_to_inch(v):\n",
    "    return v * 0.393701\n",
    "\n",
    "\n",
    "result = persons.withColumn('height_inch', cm_to_inch(persons.height))\n",
    "result.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increment a value using a Pandas UDF. The Pandas UDF receives a `pandas.Series` object and also has to return a `pandas.Series` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>height_inch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>156</td>\n",
       "      <td>Alice</td>\n",
       "      <td>female</td>\n",
       "      <td>61.417356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>181</td>\n",
       "      <td>Bob</td>\n",
       "      <td>male</td>\n",
       "      <td>71.259881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27</td>\n",
       "      <td>176</td>\n",
       "      <td>Charlie</td>\n",
       "      <td>male</td>\n",
       "      <td>69.291376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>167</td>\n",
       "      <td>Eve</td>\n",
       "      <td>female</td>\n",
       "      <td>65.748067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>172</td>\n",
       "      <td>Frances</td>\n",
       "      <td>female</td>\n",
       "      <td>67.716572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>31</td>\n",
       "      <td>191</td>\n",
       "      <td>George</td>\n",
       "      <td>female</td>\n",
       "      <td>75.196891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  height     name     sex  height_inch\n",
       "0   23     156    Alice  female    61.417356\n",
       "1   21     181      Bob    male    71.259881\n",
       "2   27     176  Charlie    male    69.291376\n",
       "3   24     167      Eve  female    65.748067\n",
       "4   19     172  Frances  female    67.716572\n",
       "5   31     191   George  female    75.196891"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import PandasUDFType, pandas_udf\n",
    "\n",
    "\n",
    "# Use pandas_udf to define a Pandas UDF\n",
    "@pandas_udf('double', PandasUDFType.SCALAR)\n",
    "# Input/output are both a pandas.Series of doubles\n",
    "def pandas_cm_to_inch(v):\n",
    "    return v * 0.393701\n",
    "\n",
    "\n",
    "result = persons.withColumn('height_inch', pandas_cm_to_inch(persons.height))\n",
    "result.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.3 Grouped Pandas Aggregate UDFs\n",
    "\n",
    "Since version 2.4.0, Spark also supports Pandas aggregation functions. This is the only way to implement custom aggregation functions in Python. Note that this type of UDF does not support partial aggregation and all data for a group or window will be loaded into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>mean_udf(age)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female</td>\n",
       "      <td>24.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>24.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sex  mean_udf(age)\n",
       "0  female          24.25\n",
       "1    male          24.00"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@pandas_udf(\"double\", PandasUDFType.GROUPED_AGG)\n",
    "def mean_udf(v):\n",
    "    return v.mean()\n",
    "\n",
    "\n",
    "result = persons.groupBy(\"sex\").agg(mean_udf(persons.age))\n",
    "result.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.4 Grouped Pandas Map UDFs\n",
    "While the example above transforms all records independently, but only one column at a time, Spark also offers a so called *grouped Pandas UDF* which operates on complete groups of records (as created by a `groupBy` method).\n",
    "\n",
    "For example let's subtract the mean of a group from all entries of a group. In Spark this could be achieved directly by using windowed aggregations, but let's use Pandas instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>avg_height_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>156</td>\n",
       "      <td>Alice</td>\n",
       "      <td>female</td>\n",
       "      <td>-15.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>167</td>\n",
       "      <td>Eve</td>\n",
       "      <td>female</td>\n",
       "      <td>-4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>172</td>\n",
       "      <td>Frances</td>\n",
       "      <td>female</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>191</td>\n",
       "      <td>George</td>\n",
       "      <td>female</td>\n",
       "      <td>19.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>181</td>\n",
       "      <td>Bob</td>\n",
       "      <td>male</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>27</td>\n",
       "      <td>176</td>\n",
       "      <td>Charlie</td>\n",
       "      <td>male</td>\n",
       "      <td>-2.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  height     name     sex  avg_height_diff\n",
       "0   23     156    Alice  female            -15.5\n",
       "1   24     167      Eve  female             -4.5\n",
       "2   19     172  Frances  female              0.5\n",
       "3   31     191   George  female             19.5\n",
       "4   21     181      Bob    male              2.5\n",
       "5   27     176  Charlie    male             -2.5"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = StructType(persons.schema.fields + [StructField(\"avg_height_diff\", FloatType())])\n",
    "\n",
    "\n",
    "@pandas_udf(schema, PandasUDFType.GROUPED_MAP)\n",
    "# Input/output are both a pandas.DataFrame\n",
    "def with_mean_height_diff(pdf):\n",
    "    return pdf.assign(avg_height_diff=pdf.height - pdf.height.mean())\n",
    "\n",
    "\n",
    "result = persons.groupby('sex').apply(with_mean_height_diff)\n",
    "result.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15 Writing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "persons.write.mode('overwrite').csv('names_ages')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16 Accessing Hive Tables\n",
    "\n",
    "PySpark supports accessing data in Hive tables. This enables to use Hive as a central database which takes the burden of specyfing the schema for a file over and over again.\n",
    "\n",
    "First let's retreieve the catalog containing all tables of a specific Hive database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "tables = spark.catalog.listTables(dbName='training')\n",
    "tables.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's read in one table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.table('training.stations')\n",
    "df.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
